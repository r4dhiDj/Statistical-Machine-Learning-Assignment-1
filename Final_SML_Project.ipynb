{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final SML Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iThovTxPs92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3a51e85-d367-4981-b110-b288f36a876f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBUFhZ9iPzis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "cf233a6d-a4ca-4543-8898-532d69b73afb"
      },
      "source": [
        "!pip install python-igraph"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-igraph\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/74/24a1afbf3abaf1d5f393b668192888d04091d1a6d106319661cd4af05406/python_igraph-0.8.2-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 5.2MB/s \n",
            "\u001b[?25hCollecting texttable>=1.6.2\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Installing collected packages: texttable, python-igraph\n",
            "Successfully installed python-igraph-0.8.2 texttable-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXa4yqhqP34z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import igraph as ig\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier,BaggingClassifier,VotingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import xgboost as xgb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHUkZRBlP5tZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training set file\n",
        "TRAIN_FILE = '/content/drive/My Drive/Colab Notebooks/train.txt'\n",
        "TEST_FILE = '/content/drive/My Drive/Colab Notebooks/test-public.txt'\n",
        "Total_edges_used_for_training_for_each_class = 50000\n",
        "Submission_file_using_bagging_classifier = '/content/drive/My Drive/Colab Notebooks/submission_bagging.csv'\n",
        "Submission_file_using_XGB_and_AGA = '/content/drive/My Drive/Colab Notebooks/submission_voting_XGB_ADA.csv'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_39LKDzQA9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_datafile(file, header = False):\n",
        "\n",
        "    source_nodes = set()\n",
        "    destination_dict = {}       # How many sources follow a given destination node \n",
        "    source_follow_count_dict = {}         # How many destination nodes does each source follow\n",
        "\n",
        "    dataset = open(file)\n",
        "    if header:\n",
        "      next(dataset)\n",
        "\n",
        "    # Creates a dictionary with destination values and count its frequencies. In addition, creates a set with all root nodes\n",
        "    for lines in dataset:\n",
        "        node_list = lines.strip().split('\\t')\n",
        "        source_nodes.add(node_list[0])\n",
        "        \n",
        "        for node in node_list[1:]:\n",
        "            destination_dict[node] = destination_dict.get(node,0) + 1\n",
        "        \n",
        "        source_follow_count_dict[node_list[0]] = len(node_list[1:])\n",
        "\n",
        "    return source_nodes, destination_dict, source_follow_count_dict"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-T-R4ycQMQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5bfbf0d5-a23c-4b43-f6bb-c3890f08258b"
      },
      "source": [
        "# Read training data \n",
        "source_nodes, destination_dict, source_follow_count_dict = read_datafile(TRAIN_FILE)\n",
        "\n",
        "print (\"Total Source nodes: %s\" % (len(source_nodes)))\n",
        "print (\"Total Destination nodes: %s\" % (len(destination_dict)))\n",
        "print (\"Total edges: %s\" % (sum(source_follow_count_dict.values())))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Source nodes: 20000\n",
            "Total Destination nodes: 4867136\n",
            "Total edges: 24004361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4qh4GLQWyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_destination_Nodes(destination_dict, min_followers = 10):\n",
        "\n",
        "    new_destination_dict = {}\n",
        "\n",
        "    # Filters the data by removing nodes that are being followed less than a threshold (default = 10)\n",
        "    for key in destination_dict:\n",
        "        if destination_dict[key] >= min_followers:\n",
        "            new_destination_dict[key] = destination_dict[key]\n",
        "    \n",
        "    return new_destination_dict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Rnhic2Qe3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "030d2ae8-51db-4924-e095-d5ebbea13d46"
      },
      "source": [
        "new_destination_dict = filter_destination_Nodes(destination_dict,10)\n",
        "\n",
        "print(\"Destination nodes after filter:  %s\" % (len(new_destination_dict)))\n",
        "print(\"Total nodes after filter: %s\" % (len(new_destination_dict) + len(source_nodes)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Destination nodes after filter:  394342\n",
            "Total nodes after filter: 414342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCr7PGx6QhAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a3bd3a3b-9a15-4329-eec6-6c5025355846"
      },
      "source": [
        "#Add nodes if filtered which are in test set\n",
        "test_source_nodes, test_destination_dict, test_source_follow_count_dict = read_datafile(TEST_FILE,True)\n",
        "print(\"Total source nodes in test file:  %s\" % (len(test_source_nodes)))\n",
        "\n",
        "nodes_in_train_after_filtering = list(source_nodes) + list(set(new_destination_dict.keys()) - source_nodes)\n",
        "\n",
        "nodes_in_test_file = list(test_source_nodes) + list(set(test_destination_dict.keys()) - test_source_nodes)\n",
        "\n",
        "total_nodes = nodes_in_train_after_filtering + list(set(nodes_in_test_file) - set(nodes_in_train_after_filtering))\n",
        "print(\"Total nodes (source + destination) to be used in training:  %s\" % (len(total_nodes)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total source nodes in test file:  2000\n",
            "Total nodes (source + destination) to be used in training:  401221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwNoWqN4Sm52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_index_for_unique_id(node_list):\n",
        "    index = {}\n",
        "    inv_index = {}\n",
        "\n",
        "    for i, node in enumerate(node_list):\n",
        "        index[i] = node\n",
        "        inv_index[node] = i\n",
        "    \n",
        "    return index, inv_index"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xZGj9ZIkUHU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bda26057-b6ae-4bc5-9490-7c3cdd47182c"
      },
      "source": [
        "# Create an index and an inverted index, in order to have a unique Id for each node\n",
        "index, inv_index = build_index_for_unique_id(total_nodes)\n",
        "print(\"Length of index:  %s\" % (len(index)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of index:  401221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSDsWBzakn1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BinarySearch(lys, val):\n",
        "    first = 0\n",
        "    last = len(lys)-1\n",
        "    index = -1\n",
        "    while (first <= last) and (index == -1):\n",
        "        mid = (first+last)//2\n",
        "        if lys[mid] == val:\n",
        "            index = mid\n",
        "        else:\n",
        "            if val<lys[mid]:\n",
        "                last = mid -1\n",
        "            else:\n",
        "                first = mid +1\n",
        "    return index"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyY4Stvskqxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_tuples(file, destination_dict, total_nodes, inv_index, max_neighbours=1000, Total_edges_used_for_training_of_each_class = 50000):\n",
        "    \n",
        "    tuples = []\n",
        "    train_tuples = []\n",
        "\n",
        "    total_nodes.sort()\n",
        "\n",
        "    # In case a source node have more than 1000 followers, we only consider max_neighbours (default = 1000)\n",
        "    with open(file) as train_data:\n",
        "        for lines in tqdm(train_data):\n",
        "            node_list = lines[:-1].split('\\t')\n",
        "            source_node = node_list[0]\n",
        "            \n",
        "            if len(node_list[1:]) > max_neighbours:\n",
        "              # We rank the nodes based on the frequency\n",
        "              rank = [-destination_dict[destnode] for destnode in node_list[1:]]              \n",
        "              sort_function = np.argsort(rank)\n",
        "              filtered_destination_list = np.array(node_list[1:])[sort_function]\n",
        "              # print(filtered_destination_list)\n",
        "            else:\n",
        "              filtered_destination_list = node_list[1:]\n",
        "\n",
        "            # We only keep the top 1000 nodes and create the tuples for them\n",
        "            for dest_node in filtered_destination_list[0:max_neighbours]:\n",
        "                if BinarySearch(total_nodes, dest_node) != -1:\n",
        "                    tuples.append((inv_index[source_node], inv_index[dest_node]))\n",
        "    \n",
        "    if Total_edges_used_for_training_of_each_class:\n",
        "        train_tuples = random.sample(tuples, Total_edges_used_for_training_of_each_class)\n",
        "    \n",
        "    return tuples, train_tuples"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qudihiPlKAl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "451ab26a-cf41-490d-8980-5347223844ab"
      },
      "source": [
        "tuples, train_tuples = build_tuples(TRAIN_FILE, destination_dict, total_nodes, inv_index, max_neighbours=2000, Total_edges_used_for_training_of_each_class=Total_edges_used_for_training_for_each_class)\n",
        "\n",
        "print (\"All Tuples (source, destination): %s\" % (len(tuples)))\n",
        "print (\"Random Train set Tuples (source, destination): %s\" % (len(train_tuples)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000it [01:20, 247.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All Tuples (source, destination): 6792218\n",
            "Random Train set Tuples (source, destination): 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Z7CpSqlUxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_igGraph(tuple_list, nodes):\n",
        "    \n",
        "    # Create a new igGraph object\n",
        "    G = ig.Graph(directed = True)\n",
        "    for node in nodes:\n",
        "        G.add_vertex(node)\n",
        "    \n",
        "    G.add_edges(tuple_list)\n",
        "                \n",
        "    return G"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocVT_BvalfI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1b6e965a-c87d-4e98-e889-e75a47f918fe"
      },
      "source": [
        "graph = build_igGraph(tuples, index.keys())\n",
        "print (\"Graph Ready\")\n",
        "ig.summary(graph)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Graph Ready\n",
            "IGRAPH DN-- 401221 6792218 -- \n",
            "+ attr: name (v)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_fj_Beul2GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_fakeEdge(G, source_nodes, inv_index, No_of_true_positive_edges, tuples):\n",
        "\n",
        "  fake_tuple_list = []\n",
        "  filtered_fake_tuple_list = []\n",
        "\n",
        "  for i in tqdm(range(0,No_of_true_positive_edges)):\n",
        "\n",
        "    n1 = inv_index[np.random.choice(list(source_nodes))] #node 1 from source list\n",
        "    n2 = random.randint(0, len(inv_index.values()))   \n",
        "    fake_tuple_list.append((n1,n2))\n",
        "\n",
        "      \n",
        "  filtered_fake_tuple_list = list(set(fake_tuple_list).difference(set(tuples)))\n",
        "  \n",
        "          \n",
        "  return filtered_fake_tuple_list"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR0Eqz46mMip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "79ff84eb-fe1b-4bb0-811a-8f063e478f8d"
      },
      "source": [
        "fake_tuple_list = build_fakeEdge(graph, source_nodes,  inv_index, len(train_tuples), tuples)\n",
        "print (\"Fake Tuples:\\t%s\" % (len(fake_tuple_list)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:04<00:00, 233.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fake Tuples:\t999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExuNyEahm12i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def friends_measure(graph, all_node_1, all_node_2):\n",
        "  \n",
        "    count = 0\n",
        "  \n",
        "    for edges_node_1 in all_node_1:\n",
        "        for edges_node_2 in all_node_2:\n",
        "            if (edges_node_1 == edges_node_2) or graph.are_connected(edges_node_1, edges_node_2) or graph.are_connected(edges_node_2, edges_node_1):\n",
        "                count+=1\n",
        "                \n",
        "    return count"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4IkwN83nEOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_Features(G, edge_list):\n",
        "  common_inbound_friends = []\n",
        "  common_outbound_friends = []\n",
        "  common_friends = []\n",
        "  friend_measure = []\n",
        "  preferential_attachment = []\n",
        "  inverse_flag = []\n",
        "  in_degree_node_1 = []\n",
        "  in_degree_node_2 = []\n",
        "  out_degree_node_1 = []\n",
        "  out_degree_node_2 = []\n",
        "  bi_degree_node_1 = []\n",
        "  bi_degree_node_2 = []\n",
        "  # shortest_paths = []\n",
        "  # adamic_adar_index = []\n",
        "  # jaccard_similarity_index = []\n",
        "  # preferential_attachment_score = []\n",
        "  # friend_tns = []\n",
        "  # similarity_dice_in = []\n",
        "  # similarity_dice_out = []\n",
        "  # similarity_dice_combined =[]\n",
        "\n",
        "  \n",
        "  # similarity_dice_in = graph.similarity_dice(pairs=edge_list,mode=ig.IN)\n",
        "  # similarity_dice_out = graph.similarity_dice(pairs=edge_list,mode=ig.OUT)\n",
        "  # similarity_dice_combined = graph.similarity_dice(pairs=edge_list,mode=ig.ALL)\n",
        "\n",
        "\n",
        "  for i, edge in tqdm(enumerate(edge_list)):\n",
        "    node_1, node_2 = edge\n",
        "    \n",
        "    # Common calculations\n",
        "    predecessor_of_node_1 = set(G.predecessors(node_1))\n",
        "    successor_of_node_1 = set(G.successors(node_1))\n",
        "    predecessor_of_node_2 = set(G.predecessors(node_2))\n",
        "    successor_of_node_2 = set(G.successors(node_2))\n",
        "    all_node_1 = predecessor_of_node_1.union(successor_of_node_1)\n",
        "    all_node_2 = predecessor_of_node_2.union(successor_of_node_2)\n",
        "    common_nodes = all_node_1.intersection(all_node_2)\n",
        "    all_nodes = all_node_1.union(all_node_2)\n",
        "\n",
        "    # Features\n",
        "    inverse_flag.append(np.int(G.are_connected(node_2,node_1)))\n",
        "\n",
        "    common_outbound_friends.append(len(successor_of_node_1.intersection(successor_of_node_2)))\n",
        "    common_inbound_friends.append(len(predecessor_of_node_1.intersection(predecessor_of_node_2)))\n",
        "    common_friends.append(len(all_node_1.union(all_node_2)))\n",
        "    friend_measure.append(friends_measure(G, all_node_1,all_node_2))\n",
        "\n",
        "    in_degree_node_1.append(len(predecessor_of_node_1))\n",
        "    in_degree_node_2.append(len(predecessor_of_node_2))\n",
        "    out_degree_node_1.append(len(successor_of_node_1))\n",
        "    out_degree_node_2.append(len(successor_of_node_2))\n",
        "    bi_degree_node_1.append(len(successor_of_node_1.intersection(predecessor_of_node_1)))\n",
        "    bi_degree_node_2.append(len(successor_of_node_2.intersection(predecessor_of_node_2)))\n",
        "    # shortest_paths.append(G.shortest_paths(source = node_1, target = node_2)[0][0])\n",
        "\n",
        "\n",
        "    # adamic_adar = sum([1.0/math.log(graph.degree(v)) for v in common_nodes])\n",
        "    # if len(all_nodes) == 0:\n",
        "    #   jaccard_similarity = 0\n",
        "    # else:\n",
        "    #   jaccard_similarity = len(common_nodes)/ float(len(all_nodes))\n",
        "\n",
        "    # if len(all_node_1) + len(all_node_2) == 1:\n",
        "    #   friend = 0\n",
        "    # else:\n",
        "    #   friend =  round((1.0/(len(all_node_1) + len(all_node_2) - 1.0)),3)\n",
        "\n",
        "    # preferential_attachment = len(all_node_1) * len(all_node_2)\n",
        "    # adamic_adar_index.append(adamic_adar)\n",
        "    # jaccard_similarity_index.append(jaccard_similarity)\n",
        "    # preferential_attachment_score.append(preferential_attachment)\n",
        "    # friend_tns.append(friend) \n",
        "  return common_inbound_friends, common_outbound_friends, common_friends, friend_measure, inverse_flag, in_degree_node_1, in_degree_node_2, out_degree_node_1, out_degree_node_2, bi_degree_node_1, bi_degree_node_2\n",
        "  # return common_inbound_friends, common_outbound_friends, common_friends, friend_measure, inverse_flag, in_degree_node_1, in_degree_node_2, out_degree_node_1, out_degree_node_2, bi_degree_node_1, bi_degree_node_2, shortest_paths, adamic_adar_index, jaccard_similarity_index, preferential_attachment_score, friend_tns, similarity_dice_in, similarity_dice_out, similarity_dice_combined"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qybrn2B3n-56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "803e928b-97eb-488b-968c-d7bcc522981f"
      },
      "source": [
        "full_tuple_list = train_tuples + fake_tuple_list\n",
        "label = np.concatenate((np.ones(len(train_tuples), dtype=int), np.zeros(len(fake_tuple_list), dtype=int)))\n",
        "\n",
        "# We create full list index\n",
        "full_list_index = {}\n",
        "full_list_inv_index = {}\n",
        "\n",
        "for i, tuple in enumerate(full_tuple_list):\n",
        "    full_list_index[i] = tuple\n",
        "    full_list_inv_index[tuple] = i\n",
        "\n",
        "print (\"label list: %s\" % (len(label)))\n",
        "print (\"Total Tuples list: %s\" % (len(full_tuple_list)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label list: 1999\n",
            "Total Tuples list: 1999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk8INrM1oFSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a216fae-0217-4b90-c1bb-02c691056cd9"
      },
      "source": [
        "#FEATURE Engineering\n",
        "\n",
        "# We create a pandas dataframe with the training set tuples\n",
        "ids = np.array(list(full_list_index.keys()))\n",
        "source_destination_nodes = np.array(full_tuple_list)\n",
        "\n",
        "common_inbound_friends, common_outbound_friends, common_friends, friend_measure, inverse_flag, in_degree_node_1, in_degree_node_2, out_degree_node_1, out_degree_node_2, bi_degree_node_1, bi_degree_node_2 = build_Features(graph, full_tuple_list)\n",
        "# common_inbound_friends, common_outbound_friends, common_friends, friend_measure, inverse_flag, in_degree_node_1, in_degree_node_2, out_degree_node_1, out_degree_node_2, bi_degree_node_1, bi_degree_node_2, shortest_paths, adamic_adar_index, jaccard_similarity_index, preferential_attachment_score, friend_tns, similarity_dice_in, similarity_dice_out, similarity_dice_combined = build_Features(graph, full_tuple_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1999it [05:16,  6.32it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYQ6wzGaoLk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c7beb93a-c705-40c1-e8db-af0d6a13c39d"
      },
      "source": [
        "print(\"Length of common_inbound_friends : %s\" %len(common_inbound_friends))\n",
        "print(\"Length of common_outbound_friends : %s\" %len(common_outbound_friends))\n",
        "print(\"Length of common_friends : %s\" %len(common_friends))\n",
        "print(\"Length of friend_measure : %s\" %len(friend_measure))\n",
        "print(\"Length of inverse_flag : %s\" %len(inverse_flag))\n",
        "print(\"Length of in_degree_node_1 : %s\" %len(in_degree_node_1))\n",
        "print(\"Length of in_degree_node_2 : %s\" %len(in_degree_node_2))\n",
        "print(\"Length of out_degree_node_1 : %s\" %len(out_degree_node_1))\n",
        "print(\"Length of out_degree_node_2 : %s\" %len(out_degree_node_2))\n",
        "print(\"Length of bi_degree_node_1 : %s\" %len(bi_degree_node_1))\n",
        "print(\"Length of bi_degree_node_2 : %s\" %len(bi_degree_node_2))\n",
        "# print(\"Length of shortest_paths : %s\" %len(shortest_paths))\n",
        "# print(\"Length of adamic_adar_index : %s\" %len(adamic_adar_index))\n",
        "# print(\"Length of jaccard_similarity_index : %s\" %len(jaccard_similarity_index))\n",
        "# print(\"Length of preferential_attachment_score : %s\" %len(preferential_attachment_score))\n",
        "# print(\"Length of friend_tns : %s\" %len(friend_tns))\n",
        "# print(\"Length of similarity_dice_in : %s\" %len(similarity_dice_in))\n",
        "# print(\"Length of similarity_dice_out : %s\" %len(similarity_dice_out))\n",
        "# print(\"Length of similarity_dice_combined : %s\" %len(similarity_dice_combined))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of common_inbound_friends : 1999\n",
            "Length of common_outbound_friends : 1999\n",
            "Length of common_friends : 1999\n",
            "Length of friend_measure : 1999\n",
            "Length of inverse_flag : 1999\n",
            "Length of in_degree_node_1 : 1999\n",
            "Length of in_degree_node_2 : 1999\n",
            "Length of out_degree_node_1 : 1999\n",
            "Length of out_degree_node_2 : 1999\n",
            "Length of bi_degree_node_1 : 1999\n",
            "Length of bi_degree_node_2 : 1999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z6MbElQ8Gqw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "5b5eca1c-e219-4d31-8223-aa795f2592ea"
      },
      "source": [
        "d = {\n",
        "    'ids': ids,\n",
        "     'Source': source_destination_nodes[:,0],\n",
        "     'destination': source_destination_nodes[:,1],\n",
        "     'inverse_flag': inverse_flag,\n",
        "     'common_inbound_friends' : common_inbound_friends,\n",
        "     'common_outbound_friends' : common_outbound_friends,\n",
        "     'common_friends' : common_friends,\n",
        "     'friend_measure' : friend_measure,\n",
        "     'in-degree source' : in_degree_node_1,\n",
        "     'in-degree destination' : in_degree_node_2,\n",
        "     'out-degree source' : out_degree_node_1,\n",
        "     'out-degree destination' : out_degree_node_2,\n",
        "     'bi-degree source' : bi_degree_node_1,\n",
        "     'bi-degree destination' : bi_degree_node_2,\n",
        "    #  'shortest paths' : shortest_paths,\n",
        "    #  'Adamic adar index' : adamic_adar_index,\n",
        "    #  'Jaccard Similarity index' : jaccard_similarity_index,\n",
        "    #  'preferential_attachment_score' : preferential_attachment_score,\n",
        "    #  'friend_tns' : friend_tns,\n",
        "    #  'similarity dice in' : similarity_dice_in,\n",
        "    #  'similarity dice combined' : similarity_dice_combined,\n",
        "    #  'similarity dice out' : similarity_dice_out,\n",
        "     'label' : label\n",
        "     }\n",
        "\n",
        "df = pd.DataFrame(data=d)\n",
        "\n",
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ids</th>\n",
              "      <th>Source</th>\n",
              "      <th>destination</th>\n",
              "      <th>inverse_flag</th>\n",
              "      <th>common_inbound_friends</th>\n",
              "      <th>common_outbound_friends</th>\n",
              "      <th>common_friends</th>\n",
              "      <th>friend_measure</th>\n",
              "      <th>in-degree source</th>\n",
              "      <th>in-degree destination</th>\n",
              "      <th>out-degree source</th>\n",
              "      <th>out-degree destination</th>\n",
              "      <th>bi-degree source</th>\n",
              "      <th>bi-degree destination</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14389</td>\n",
              "      <td>139164</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>527</td>\n",
              "      <td>535</td>\n",
              "      <td>41</td>\n",
              "      <td>8</td>\n",
              "      <td>503</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>19380</td>\n",
              "      <td>193201</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>916</td>\n",
              "      <td>2982</td>\n",
              "      <td>5</td>\n",
              "      <td>51</td>\n",
              "      <td>865</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>9302</td>\n",
              "      <td>232333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>2477</td>\n",
              "      <td>238</td>\n",
              "      <td>4</td>\n",
              "      <td>1999</td>\n",
              "      <td>0</td>\n",
              "      <td>226</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>19348</td>\n",
              "      <td>243716</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>2714</td>\n",
              "      <td>58392</td>\n",
              "      <td>873</td>\n",
              "      <td>129</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>266</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2630</td>\n",
              "      <td>201994</td>\n",
              "      <td>0</td>\n",
              "      <td>175</td>\n",
              "      <td>0</td>\n",
              "      <td>2577</td>\n",
              "      <td>275018</td>\n",
              "      <td>740</td>\n",
              "      <td>402</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>386</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>1994</td>\n",
              "      <td>8046</td>\n",
              "      <td>201397</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>195</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>5</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1995</td>\n",
              "      <td>2961</td>\n",
              "      <td>333271</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2890</td>\n",
              "      <td>535</td>\n",
              "      <td>2431</td>\n",
              "      <td>9</td>\n",
              "      <td>546</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1996</td>\n",
              "      <td>19249</td>\n",
              "      <td>399245</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>272</td>\n",
              "      <td>2</td>\n",
              "      <td>102</td>\n",
              "      <td>1</td>\n",
              "      <td>214</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1997</td>\n",
              "      <td>15607</td>\n",
              "      <td>134765</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>124</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1998</td>\n",
              "      <td>1835</td>\n",
              "      <td>256877</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>3</td>\n",
              "      <td>125</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1999 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ids  Source  destination  ...  bi-degree source  bi-degree destination  label\n",
              "0        0   14389       139164  ...                25                      0      1\n",
              "1        1   19380       193201  ...                 4                      0      1\n",
              "2        2    9302       232333  ...               226                      0      1\n",
              "3        3   19348       243716  ...               266                      0      1\n",
              "4        4    2630       201994  ...               386                      0      1\n",
              "...    ...     ...          ...  ...               ...                    ...    ...\n",
              "1994  1994    8046       201397  ...                20                      0      0\n",
              "1995  1995    2961       333271  ...                94                      0      0\n",
              "1996  1996   19249       399245  ...                45                      0      0\n",
              "1997  1997   15607       134765  ...                 9                      0      0\n",
              "1998  1998    1835       256877  ...                17                      0      0\n",
              "\n",
              "[1999 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtYHhm8584SO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fab693b6-0906-411e-ace1-db1c2555a42e"
      },
      "source": [
        "# We split the training set into train and a holdout set\n",
        "df_train, df_holdout = train_test_split(df, test_size=0.3, random_state=42)\n",
        "\n",
        "Y_train = df_train['label']\n",
        "Y_holdout = df_holdout['label']\n",
        "X_train = df_train.drop(['label', 'Source', 'destination', 'ids'], axis = 1)\n",
        "X_holdout = df_holdout.drop(['label', 'Source', 'destination', 'ids'], axis = 1)\n",
        "\n",
        "print (\"Train set length: %s\" % (len(df_train)))\n",
        "print (\"Holdout set length: %s\" % (len(df_holdout)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set length: 1399\n",
            "Holdout set length: 600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iSbeuSe9G1x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "4a3d8eb8-3076-42ae-8855-d33cae38fcd4"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inverse_flag</th>\n",
              "      <th>common_inbound_friends</th>\n",
              "      <th>common_outbound_friends</th>\n",
              "      <th>common_friends</th>\n",
              "      <th>friend_measure</th>\n",
              "      <th>in-degree source</th>\n",
              "      <th>in-degree destination</th>\n",
              "      <th>out-degree source</th>\n",
              "      <th>out-degree destination</th>\n",
              "      <th>bi-degree source</th>\n",
              "      <th>bi-degree destination</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2042</td>\n",
              "      <td>5392</td>\n",
              "      <td>133</td>\n",
              "      <td>41</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>843</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>294</td>\n",
              "      <td>2079</td>\n",
              "      <td>47</td>\n",
              "      <td>84</td>\n",
              "      <td>178</td>\n",
              "      <td>79</td>\n",
              "      <td>30</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1652</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>505</td>\n",
              "      <td>27</td>\n",
              "      <td>337</td>\n",
              "      <td>10</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1555</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>222</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1172</td>\n",
              "      <td>51</td>\n",
              "      <td>48</td>\n",
              "      <td>3</td>\n",
              "      <td>1167</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3667</td>\n",
              "      <td>594</td>\n",
              "      <td>2035</td>\n",
              "      <td>7</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>374</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>2665</td>\n",
              "      <td>231922</td>\n",
              "      <td>57</td>\n",
              "      <td>731</td>\n",
              "      <td>2000</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>5</td>\n",
              "      <td>70</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>280</td>\n",
              "      <td>448</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "      <td>200</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1399 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      inverse_flag  ...  bi-degree destination\n",
              "557              0  ...                      0\n",
              "843              0  ...                     37\n",
              "1652             0  ...                      0\n",
              "1555             0  ...                      0\n",
              "1160             0  ...                      0\n",
              "...            ...  ...                    ...\n",
              "1130             0  ...                      0\n",
              "1294             0  ...                      0\n",
              "860              0  ...                      0\n",
              "1459             0  ...                      0\n",
              "1126             0  ...                      0\n",
              "\n",
              "[1399 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILahtvkNBnUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "9ad3e951-0e84-4c6f-f000-70526305e546"
      },
      "source": [
        "#For AdaBoost Classifier\n",
        "n_estimators = np.linspace(600, 1500, 10, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "\n",
        "for i in tqdm(n_estimators):\n",
        "    dt = AdaBoostClassifier(n_estimators=int(i))\n",
        "    dt.fit(X_train, Y_train)    \n",
        "    Y_prediction = dt.predict(X_train)\n",
        "\n",
        "    #append results of accuracy\n",
        "    train_results.append(roc_auc_score(Y_train, Y_prediction))\n",
        "    \n",
        "    #now again for test data\n",
        "    Y_prediction = dt.predict(X_holdout)\n",
        "    #append results of accuracy\n",
        "    test_results.append(roc_auc_score(Y_holdout, Y_prediction))\n",
        "\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "import matplotlib.pyplot as plt\n",
        "line1, = plt.plot(n_estimators, train_results, 'b', label='Train accuracy')\n",
        "line2, = plt.plot(n_estimators, test_results, 'r', label= 'Test accuracy')\n",
        "\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('Accuracy score')\n",
        "plt.xlabel('n_estimators')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:31<00:00,  3.19s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'n_estimators')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ai1dUgh9bRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "8fdc1629-4861-44a6-acb1-2e11f578cc50"
      },
      "source": [
        "#For Random Forest\n",
        "n_estimators = np.linspace(100, 1000, 10, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "\n",
        "for i in tqdm(n_estimators):\n",
        "    dt = RandomForestClassifier(max_depth=8,n_estimators=int(i),n_jobs=-1)\n",
        "    dt.fit(X_train, Y_train)    \n",
        "    Y_prediction = dt.predict(X_train)\n",
        "\n",
        "    #append results of accuracy\n",
        "    train_results.append(roc_auc_score(Y_train, Y_prediction))\n",
        "    \n",
        "    #now again for test data\n",
        "    Y_prediction = dt.predict(X_holdout)\n",
        "    #append results of accuracy\n",
        "    test_results.append(roc_auc_score(Y_holdout, Y_prediction))\n",
        "\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "import matplotlib.pyplot as plt\n",
        "line1, = plt.plot(n_estimators, train_results, 'b', label='Train accuracy')\n",
        "line2, = plt.plot(n_estimators, test_results, 'r', label= 'Test accuracy')\n",
        "\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('Accuracy score')\n",
        "plt.xlabel('n_estimators')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:18<00:00,  1.89s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'n_estimators')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIdFJ-g-9iTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "bed9efcf-6c12-4a24-8873-193ea98ed240"
      },
      "source": [
        "max_depths = np.linspace(1, 50, 50, endpoint=True)\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "\n",
        "for i in tqdm(max_depths):\n",
        "    dt = RandomForestClassifier(max_depth=i,n_jobs=-1)\n",
        "    dt.fit(X_train, Y_train)\n",
        "    Y_prediction = dt.predict(X_train)    \n",
        "    #append results of accuracy\n",
        "    train_results.append(roc_auc_score(Y_train, Y_prediction))\n",
        "    \n",
        "    #now again for test data\n",
        "    Y_prediction = dt.predict(X_holdout)\n",
        "    errors = abs(Y_prediction - Y_holdout)\n",
        "    #append results of accuracy\n",
        "    test_results.append(roc_auc_score(Y_holdout, Y_prediction))\n",
        "\n",
        "\n",
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "import matplotlib.pyplot as plt\n",
        "line1, = plt.plot(max_depths, train_results, 'b', label='Train accuracy')\n",
        "line2, = plt.plot(max_depths, test_results, 'r', label= 'Test accuracy')\n",
        "\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('Accuracy score')\n",
        "plt.xlabel('Tree depth')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:27<00:00,  1.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Tree depth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-2plStJAgA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "outputId": "fce24377-2b7a-4333-f75f-0447fd07d82b"
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "names = [\n",
        "         \"K neighbor\",\n",
        "         \"decision tree\",\n",
        "         \"Logistic Regression\",\n",
        "         \"AdaBoostClassifier\",\n",
        "         \"xgboost\",\n",
        "         \"RandomForestClassifier\"\n",
        "        ]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    LogisticRegression(),\n",
        "    AdaBoostClassifier(),\n",
        "    xgb.XGBClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "] \n",
        "\n",
        "parameters = [\n",
        "              {\n",
        "                  'clf__n_neighbors':[15,20,25,30,35,40,45,50],\n",
        "                  'clf__p':[1,2,3]\n",
        "              },\n",
        "              {\n",
        "                  'clf__max_depth': [1,2,3,4,5],\n",
        "                  'clf__max_features': [None, \"auto\", \"sqrt\", \"log2\"]\n",
        "              },\n",
        "              {\n",
        "                    'clf__C':[0.01,0.1],\n",
        "                    'clf__max_iter':[50,100,150,200],\n",
        "                    'clf__penalty':['l2']\n",
        "               \n",
        "              },\n",
        "              {\n",
        "                  'clf__learning_rate' : [1],\n",
        "                  'clf__n_estimators' : [400,450,500,600,700,800],\n",
        "                  'clf__random_state' : [0],\n",
        "                  'clf__algorithm' : ['SAMME.R']\n",
        "              },\n",
        "              {\n",
        "                  'clf__learning_rate' : [0.001,0.01,0.1],\n",
        "                  'clf__max_depth' : [2,3,4,5,6,7],\n",
        "                  'clf__min_child_weight' : [1,2,3,4,5,6],\n",
        "                  'clf__subsample' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
        "              },\n",
        "              {\n",
        "                  'clf__n_estimators' : [100,200,300,400],\n",
        "                  'clf__max_depth' : [8]\n",
        "              }\n",
        "                \n",
        "             ]\n",
        "scaler = StandardScaler()\n",
        "model_params_score = []\n",
        "for name, classifier, params in zip(names, classifiers, parameters):\n",
        "    steps=[('scaler', scaler), ('clf', classifier)]\n",
        "    pipe = Pipeline(steps)\n",
        "    print(\"Paprameters for the model are: \", pipe.get_params().keys())\n",
        "    gs_clf = GridSearchCV(pipe, param_grid=params, cv=5,n_jobs=-1)\n",
        "    gs_clf.fit(X_train, Y_train)\n",
        "    Y_prediction = gs_clf.predict(X_holdout)\n",
        "    model_params_score.append([classifier,roc_auc_score(Y_holdout, Y_prediction),gs_clf.best_params_])\n",
        "    \n",
        "    print(\"--------------------------------------------------------------------------\")\n",
        "    print(\"%s\\n\\n\\t\\tAUC score: %s\" % (classifier , roc_auc_score(Y_holdout, Y_prediction)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__algorithm', 'clf__leaf_size', 'clf__metric', 'clf__metric_params', 'clf__n_jobs', 'clf__n_neighbors', 'clf__p', 'clf__weights'])\n",
            "--------------------------------------------------------------------------\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform')\n",
            "\n",
            "\t\tAUC score: 0.8366212836899137\n",
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__ccp_alpha', 'clf__class_weight', 'clf__criterion', 'clf__max_depth', 'clf__max_features', 'clf__max_leaf_nodes', 'clf__min_impurity_decrease', 'clf__min_impurity_split', 'clf__min_samples_leaf', 'clf__min_samples_split', 'clf__min_weight_fraction_leaf', 'clf__presort', 'clf__random_state', 'clf__splitter'])\n",
            "--------------------------------------------------------------------------\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best')\n",
            "\n",
            "\t\tAUC score: 0.9599888858016116\n",
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__C', 'clf__class_weight', 'clf__dual', 'clf__fit_intercept', 'clf__intercept_scaling', 'clf__l1_ratio', 'clf__max_iter', 'clf__multi_class', 'clf__n_jobs', 'clf__penalty', 'clf__random_state', 'clf__solver', 'clf__tol', 'clf__verbose', 'clf__warm_start'])\n",
            "--------------------------------------------------------------------------\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\t\tAUC score: 0.8028063350930814\n",
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__algorithm', 'clf__base_estimator', 'clf__learning_rate', 'clf__n_estimators', 'clf__random_state'])\n",
            "--------------------------------------------------------------------------\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=None)\n",
            "\n",
            "\t\tAUC score: 0.968463462072798\n",
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__base_score', 'clf__booster', 'clf__colsample_bylevel', 'clf__colsample_bynode', 'clf__colsample_bytree', 'clf__gamma', 'clf__learning_rate', 'clf__max_delta_step', 'clf__max_depth', 'clf__min_child_weight', 'clf__missing', 'clf__n_estimators', 'clf__n_jobs', 'clf__nthread', 'clf__objective', 'clf__random_state', 'clf__reg_alpha', 'clf__reg_lambda', 'clf__scale_pos_weight', 'clf__seed', 'clf__silent', 'clf__subsample', 'clf__verbosity'])\n",
            "--------------------------------------------------------------------------\n",
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
            "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
            "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
            "              nthread=None, objective='binary:logistic', random_state=0,\n",
            "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
            "              silent=None, subsample=1, verbosity=1)\n",
            "\n",
            "\t\tAUC score: 0.9699916643512086\n",
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__bootstrap', 'clf__ccp_alpha', 'clf__class_weight', 'clf__criterion', 'clf__max_depth', 'clf__max_features', 'clf__max_leaf_nodes', 'clf__max_samples', 'clf__min_impurity_decrease', 'clf__min_impurity_split', 'clf__min_samples_leaf', 'clf__min_samples_split', 'clf__min_weight_fraction_leaf', 'clf__n_estimators', 'clf__n_jobs', 'clf__oob_score', 'clf__random_state', 'clf__verbose', 'clf__warm_start'])\n",
            "--------------------------------------------------------------------------\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "\n",
            "\t\tAUC score: 0.9715754376215614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGfWtMI8Aydn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "5ceb9a3c-a187-4bc3-c601-d66288772e9b"
      },
      "source": [
        "model_params_score"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                       metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                       weights='uniform'),\n",
              "  0.8366212836899137,\n",
              "  {'clf__n_neighbors': 15, 'clf__p': 1}],\n",
              " [DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=2,\n",
              "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                         random_state=None, splitter='best'),\n",
              "  0.9599888858016116,\n",
              "  {'clf__max_depth': 4, 'clf__max_features': None}],\n",
              " [LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                     random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                     warm_start=False),\n",
              "  0.8028063350930814,\n",
              "  {'clf__C': 0.1, 'clf__max_iter': 50, 'clf__penalty': 'l2'}],\n",
              " [AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                     n_estimators=50, random_state=None),\n",
              "  0.968463462072798,\n",
              "  {'clf__algorithm': 'SAMME.R',\n",
              "   'clf__learning_rate': 1,\n",
              "   'clf__n_estimators': 800,\n",
              "   'clf__random_state': 0}],\n",
              " [XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "                colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "                learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "                min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "                nthread=None, objective='binary:logistic', random_state=0,\n",
              "                reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "                silent=None, subsample=1, verbosity=1),\n",
              "  0.9699916643512086,\n",
              "  {'clf__learning_rate': 0.1,\n",
              "   'clf__max_depth': 3,\n",
              "   'clf__min_child_weight': 2,\n",
              "   'clf__subsample': 0.9}],\n",
              " [RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                         criterion='gini', max_depth=None, max_features='auto',\n",
              "                         max_leaf_nodes=None, max_samples=None,\n",
              "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                         min_samples_leaf=1, min_samples_split=2,\n",
              "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                         n_jobs=None, oob_score=False, random_state=None,\n",
              "                         verbose=0, warm_start=False),\n",
              "  0.9715754376215614,\n",
              "  {'clf__max_depth': 8, 'clf__n_estimators': 300}]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W_if8aeA0lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a5fdc6a4-37a2-4fd6-f4b0-b3c79bf59c69"
      },
      "source": [
        "#get best index as a model\n",
        "best_value =0.0\n",
        "index = 0\n",
        "for counter, info in enumerate(model_params_score):\n",
        "    if(info[1]>best_value):\n",
        "        best_value = info[1]\n",
        "        index = counter\n",
        "        \n",
        "# retrained the model based on the best one for fitting the test data\n",
        "classifier = model_params_score[index][0]\n",
        "steps=[('scaler', scaler), ('clf', classifier)]\n",
        "pipe = Pipeline(steps)  \n",
        "pipe.set_params(**model_params_score[index][2])\n",
        "pipe.fit(X_train, Y_train)\n",
        "Y_prediction = pipe.predict(X_holdout)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------\")\n",
        "print(\"%s\\n\\n\\t\\tAUC score: %s\" % (classifier , roc_auc_score(Y_holdout, Y_prediction)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=8, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)\n",
            "\n",
            "\t\tAUC score: 0.9682411781050292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq-zlKjh9lFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "67920dd6-4e5c-402d-ca5b-332b61c326a8"
      },
      "source": [
        "# voting using XGBOOST and ADABOOST \n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "voting_params_score=[]\n",
        "eclf = VotingClassifier(estimators=[ \n",
        "    ('adaboost', AdaBoostClassifier()),\n",
        "    ('xgb', xgb.XGBClassifier()),\n",
        "    \n",
        "    ], voting='soft'\n",
        ")\n",
        "\n",
        "#Use the key for the classifier followed by __ and the attribute\n",
        "params = {'clf__adaboost__algorithm':['SAMME.R'],\n",
        "          'clf__adaboost__learning_rate':[0.1,1],\n",
        "          'clf__adaboost__n_estimators':[1000],\n",
        "          \n",
        "          \n",
        "          'clf__xgb__booster':['gbtree'],\n",
        "          'clf__xgb__eval': ['auc'],\n",
        "          'clf__xgb__gamma':[0],\n",
        "          'clf__xgb__lambda':[1],\n",
        "          'clf__xgb__learning_rate': [0.1],\n",
        "          'clf__xgb__max_depth':[100],\n",
        "          'clf__xgb__min_child_weight':[10],\n",
        "          'clf__xgb__subsample':[1]\n",
        "         }\n",
        "\n",
        "steps=[('scaler', scaler), ('clf', eclf)]\n",
        "pipe = Pipeline(steps)\n",
        "print(\"Paprameters for the model are: \", pipe.get_params().keys())\n",
        "\n",
        "gs_clf = GridSearchCV(pipe, param_grid=params, cv=5,n_jobs=-1)\n",
        "gs_clf.fit(X_train, Y_train)\n",
        "Y_prediction = gs_clf.predict(X_holdout)\n",
        "voting_params_score.append([eclf,roc_auc_score(Y_holdout, Y_prediction),gs_clf.best_params_])\n",
        "    \n",
        "print(\"--------------------------------------------------------------------------\")\n",
        "print(\"%s\\n\\n\\t\\tAUC score: %s\" % (eclf , roc_auc_score(Y_holdout, Y_prediction)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__estimators', 'clf__flatten_transform', 'clf__n_jobs', 'clf__voting', 'clf__weights', 'clf__adaboost', 'clf__xgb', 'clf__adaboost__algorithm', 'clf__adaboost__base_estimator', 'clf__adaboost__learning_rate', 'clf__adaboost__n_estimators', 'clf__adaboost__random_state', 'clf__xgb__base_score', 'clf__xgb__booster', 'clf__xgb__colsample_bylevel', 'clf__xgb__colsample_bynode', 'clf__xgb__colsample_bytree', 'clf__xgb__gamma', 'clf__xgb__learning_rate', 'clf__xgb__max_delta_step', 'clf__xgb__max_depth', 'clf__xgb__min_child_weight', 'clf__xgb__missing', 'clf__xgb__n_estimators', 'clf__xgb__n_jobs', 'clf__xgb__nthread', 'clf__xgb__objective', 'clf__xgb__random_state', 'clf__xgb__reg_alpha', 'clf__xgb__reg_lambda', 'clf__xgb__scale_pos_weight', 'clf__xgb__seed', 'clf__xgb__silent', 'clf__xgb__subsample', 'clf__xgb__verbosity'])\n",
            "--------------------------------------------------------------------------\n",
            "VotingClassifier(estimators=[('adaboost',\n",
            "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
            "                                                 base_estimator=None,\n",
            "                                                 learning_rate=1.0,\n",
            "                                                 n_estimators=50,\n",
            "                                                 random_state=None)),\n",
            "                             ('xgb',\n",
            "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
            "                                            colsample_bylevel=1,\n",
            "                                            colsample_bynode=1,\n",
            "                                            colsample_bytree=1, gamma=0,\n",
            "                                            learning_rate=0.1, max_delta_step=0,\n",
            "                                            max_depth=3, min_child_weight=1,\n",
            "                                            missing=None, n_estimators=100,\n",
            "                                            n_jobs=1, nthread=None,\n",
            "                                            objective='binary:logistic',\n",
            "                                            random_state=0, reg_alpha=0,\n",
            "                                            reg_lambda=1, scale_pos_weight=1,\n",
            "                                            seed=None, silent=None, subsample=1,\n",
            "                                            verbosity=1))],\n",
            "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
            "                 weights=None)\n",
            "\n",
            "\t\tAUC score: 0.9666574048346763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxOm292_9ue7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "56dc505d-0be1-43fc-867a-763dcd831c3c"
      },
      "source": [
        "# We read the test data\n",
        "test_edge_list = []\n",
        "\n",
        "with open(TEST_FILE) as test_data:\n",
        "    for i , lines in enumerate(test_data):\n",
        "        \n",
        "        if i == 0:                              # Skips the header\n",
        "            continue;\n",
        "        \n",
        "        node_list = lines[:-1].split('\\t')\n",
        "        test_edge_list.append((inv_index[node_list[1]], inv_index[node_list[2]]))\n",
        "\n",
        "common_inbound_friends, common_outbound_friends, common_friends, friend_measure, inverse_flag, in_degree_node_1, in_degree_node_2, out_degree_node_1, out_degree_node_2, bi_degree_node_1, bi_degree_node_2 = build_Features(graph, test_edge_list)\n",
        "# common_inbound_friends, common_outbound_friends, common_friends, friend_measure, inverse_flag, in_degree_node_1, in_degree_node_2, out_degree_node_1, out_degree_node_2, bi_degree_node_1, bi_degree_node_2, shortest_paths, adamic_adar_index, jaccard_similarity_index, preferential_attachment_score, friend_tns, similarity_dice_in, similarity_dice_out, similarity_dice_combined = build_Features(graph, test_edge_list)\n",
        "\n",
        "d_test = {\n",
        "     'inverse_flag': inverse_flag,\n",
        "     'common_inbound_friends' : common_inbound_friends,\n",
        "     'common_outbound_friends' : common_outbound_friends,\n",
        "     'common_friends' : common_friends,\n",
        "     'friend_measure' : friend_measure,\n",
        "     'in-degree source' : in_degree_node_1,\n",
        "     'in-degree destination' : in_degree_node_2,\n",
        "     'out-degree source' : out_degree_node_1,\n",
        "     'out-degree destination' : out_degree_node_2,\n",
        "     'bi-degree source' : bi_degree_node_1,\n",
        "     'bi-degree destination' : bi_degree_node_2,\n",
        "    #  'shortest paths' : shortest_paths,\n",
        "    #  'Adamic adar index' : adamic_adar_index,\n",
        "    #  'Jaccard Similarity index' : jaccard_similarity_index,\n",
        "    #  'preferential_attachment_score' : preferential_attachment_score,\n",
        "    #  'friend_tns' : friend_tns,\n",
        "    #  'similarity dice in' : similarity_dice_in,\n",
        "    #  'similarity dice combined' : similarity_dice_combined,\n",
        "    #  'similarity dice out' : similarity_dice_out,\n",
        "     }\n",
        "\n",
        "\n",
        "df_test = pd.DataFrame(data=d_test)\n",
        "df_test"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000it [01:18, 25.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inverse_flag</th>\n",
              "      <th>common_inbound_friends</th>\n",
              "      <th>common_outbound_friends</th>\n",
              "      <th>common_friends</th>\n",
              "      <th>friend_measure</th>\n",
              "      <th>in-degree source</th>\n",
              "      <th>in-degree destination</th>\n",
              "      <th>out-degree source</th>\n",
              "      <th>out-degree destination</th>\n",
              "      <th>bi-degree source</th>\n",
              "      <th>bi-degree destination</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>206</td>\n",
              "      <td>283</td>\n",
              "      <td>77</td>\n",
              "      <td>14</td>\n",
              "      <td>147</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>391</td>\n",
              "      <td>119</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>381</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>83</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      inverse_flag  ...  bi-degree destination\n",
              "0                0  ...                      0\n",
              "1                0  ...                      0\n",
              "2                0  ...                      0\n",
              "3                0  ...                      0\n",
              "4                0  ...                      0\n",
              "...            ...  ...                    ...\n",
              "1995             0  ...                      0\n",
              "1996             0  ...                      0\n",
              "1997             0  ...                      0\n",
              "1998             0  ...                      0\n",
              "1999             0  ...                      0\n",
              "\n",
              "[2000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axpyq2e3EQO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dec5f1aa-0d6b-425b-c627-959d155dbc70"
      },
      "source": [
        "# retrained the model based on the best one for fitting the test data\n",
        "classifier = eclf\n",
        "steps=[('scaler', scaler), ('clf', classifier)]\n",
        "pipe = Pipeline(steps)  \n",
        "pipe.set_params(**voting_params_score[0][2])\n",
        "pipe.fit(X_train, Y_train)\n",
        "Y_prediction = pipe.predict(X_holdout)\n",
        "y_predicted = pipe.predict_proba(df_test)[:,1]\n",
        "y_predicted\n",
        "#"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.23885701, 0.23684216, 0.62491048, ..., 0.23959268, 0.23902469,\n",
              "       0.23369316])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gz5h4c2EoAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct submission file\n",
        "Id = [i for i in range(1, 2001)]\n",
        "data = {\"Id\":Id, \"Predicted\":y_predicted}\n",
        "df_submit = pd.DataFrame(data)\n",
        "df_submit.to_csv(Submission_file_using_XGB_and_AGA, index = False, header=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBdfKQrTE2eF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "8ce3891f-73b7-41eb-f172-9fd752897e11"
      },
      "source": [
        "# voting using RandomForest, KNeighborsClassifier and BaggingClassifier \n",
        "\n",
        "voting_params_score=[]\n",
        "eclf = VotingClassifier(estimators=[ \n",
        "    ('randomForest', RandomForestClassifier()),\n",
        "    ('knn', KNeighborsClassifier()),\n",
        "    ('bagging',BaggingClassifier()),\n",
        "    \n",
        "    ], voting='soft'\n",
        ")\n",
        "\n",
        "#Use the key for the classifier followed by __ and the attribute\n",
        "params = {\n",
        "              'clf__randomForest__n_estimators' : [300],\n",
        "              'clf__randomForest__max_depth' : [8],\n",
        "          \n",
        "              'clf__knn__n_neighbors':[5,10,15],\n",
        "              'clf__knn__p':[2],\n",
        "        \n",
        "              'clf__bagging__n_estimators' : [10,50,100],\n",
        "               \n",
        "         }\n",
        "\n",
        "steps=[('scaler', scaler), ('clf', eclf)]\n",
        "pipe = Pipeline(steps)\n",
        "print(\"Paprameters for the model are: \", pipe.get_params().keys())\n",
        "\n",
        "gs_clf = GridSearchCV(pipe, param_grid=params, cv=5,n_jobs=-1)\n",
        "gs_clf.fit(X_train, Y_train)\n",
        "Y_prediction = gs_clf.predict(X_holdout)\n",
        "voting_params_score.append([eclf,roc_auc_score(Y_holdout, Y_prediction),gs_clf.best_params_])\n",
        "    \n",
        "print(\"--------------------------------------------------------------------------\")\n",
        "print(\"%s\\n\\n\\t\\tAUC score: %s\" % (eclf , roc_auc_score(Y_holdout, Y_prediction)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paprameters for the model are:  dict_keys(['memory', 'steps', 'verbose', 'scaler', 'clf', 'scaler__copy', 'scaler__with_mean', 'scaler__with_std', 'clf__estimators', 'clf__flatten_transform', 'clf__n_jobs', 'clf__voting', 'clf__weights', 'clf__randomForest', 'clf__knn', 'clf__bagging', 'clf__randomForest__bootstrap', 'clf__randomForest__ccp_alpha', 'clf__randomForest__class_weight', 'clf__randomForest__criterion', 'clf__randomForest__max_depth', 'clf__randomForest__max_features', 'clf__randomForest__max_leaf_nodes', 'clf__randomForest__max_samples', 'clf__randomForest__min_impurity_decrease', 'clf__randomForest__min_impurity_split', 'clf__randomForest__min_samples_leaf', 'clf__randomForest__min_samples_split', 'clf__randomForest__min_weight_fraction_leaf', 'clf__randomForest__n_estimators', 'clf__randomForest__n_jobs', 'clf__randomForest__oob_score', 'clf__randomForest__random_state', 'clf__randomForest__verbose', 'clf__randomForest__warm_start', 'clf__knn__algorithm', 'clf__knn__leaf_size', 'clf__knn__metric', 'clf__knn__metric_params', 'clf__knn__n_jobs', 'clf__knn__n_neighbors', 'clf__knn__p', 'clf__knn__weights', 'clf__bagging__base_estimator', 'clf__bagging__bootstrap', 'clf__bagging__bootstrap_features', 'clf__bagging__max_features', 'clf__bagging__max_samples', 'clf__bagging__n_estimators', 'clf__bagging__n_jobs', 'clf__bagging__oob_score', 'clf__bagging__random_state', 'clf__bagging__verbose', 'clf__bagging__warm_start'])\n",
            "--------------------------------------------------------------------------\n",
            "VotingClassifier(estimators=[('randomForest',\n",
            "                              RandomForestClassifier(bootstrap=True,\n",
            "                                                     ccp_alpha=0.0,\n",
            "                                                     class_weight=None,\n",
            "                                                     criterion='gini',\n",
            "                                                     max_depth=None,\n",
            "                                                     max_features='auto',\n",
            "                                                     max_leaf_nodes=None,\n",
            "                                                     max_samples=None,\n",
            "                                                     min_impurity_decrease=0.0,\n",
            "                                                     min_impurity_split=None,\n",
            "                                                     min_samples_leaf=1,\n",
            "                                                     min_samples_split=2,\n",
            "                                                     min_weight_fraction_leaf=0.0,\n",
            "                                                     n_estimators=100,\n",
            "                                                     n_jobs=None...\n",
            "                                                   metric='minkowski',\n",
            "                                                   metric_params=None,\n",
            "                                                   n_jobs=None, n_neighbors=5,\n",
            "                                                   p=2, weights='uniform')),\n",
            "                             ('bagging',\n",
            "                              BaggingClassifier(base_estimator=None,\n",
            "                                                bootstrap=True,\n",
            "                                                bootstrap_features=False,\n",
            "                                                max_features=1.0,\n",
            "                                                max_samples=1.0,\n",
            "                                                n_estimators=10, n_jobs=None,\n",
            "                                                oob_score=False,\n",
            "                                                random_state=None, verbose=0,\n",
            "                                                warm_start=False))],\n",
            "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
            "                 weights=None)\n",
            "\n",
            "\t\tAUC score: 0.9569324812447901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tvZzXaBFHD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9bdfe843-5a4c-48ee-946b-39ffe23afd22"
      },
      "source": [
        "# retrained the model based on the best one for fitting the test data\n",
        "classifier = eclf\n",
        "steps=[('scaler', scaler), ('clf', classifier)]\n",
        "pipe = Pipeline(steps)  \n",
        "pipe.set_params(**voting_params_score[0][2])\n",
        "pipe.fit(X_train, Y_train)\n",
        "Y_prediction = pipe.predict(X_holdout)\n",
        "y_predicted = pipe.predict_proba(df_test)[:,1]\n",
        "y_predicted\n",
        "#"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.48823549e-04, 1.30034125e-03, 4.56362427e-01, ...,\n",
              "       1.09193251e-03, 9.52300454e-05, 4.09328652e-04])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8p_Cs3ZFKoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct submission file\n",
        "Id = [i for i in range(1, 2001)]\n",
        "data = {\"Id\":Id, \"Predicted\":y_predicted}\n",
        "df_submit = pd.DataFrame(data)\n",
        "df_submit.to_csv(Submission_file_using_bagging_classifier, index = False, header=True)"
      ],
      "execution_count": 39,
      "outputs": []
    }
  ]
}